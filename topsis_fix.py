import mysql.connector
from mysql.connector import Error
import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
from datetime import datetime

# --- C·∫§U H√åNH TRANG WEB ---
st.set_page_config(
    page_title="TOPSIS - Ph√¢n t√≠ch R·ªßi ro C·ªï phi·∫øu",
    page_icon="‚öñÔ∏è",
    layout="wide"
)

# --- C√ÅC BI·∫æN C·ªê ƒê·ªäNH CHO LU·ªíNG DATABASE ---
DB_CRITERIA = ['RSI', 'MACD', 'trailingPE_snapshot', 'marketCap_snapshot', 'Returns']
DB_IMPACTS = {
    'RSI': 'Cost',
    'MACD': 'Benefit',
    'trailingPE_snapshot': 'Cost',
    'marketCap_snapshot': 'Benefit',
    'Returns': 'Benefit'
}

# --- H√ÄM K·∫æT N·ªêI DATABASE ---
@st.cache_resource
def get_db_connection():
    """T·∫°o k·∫øt n·ªëi t·ªõi MySQL database"""
    try:
        connection = mysql.connector.connect(
            host='127.0.0.1',
            user='root',
            password='130225',
            database='tickets',
            port=3306
        )
        return connection
    except Error as e:
        st.error(f"‚ùå L·ªói k·∫øt n·ªëi database: {e}")
        return None

# --- H√ÄM L·∫§Y D·ªÆ LI·ªÜU ---
@st.cache_data
def get_stock_data(tickers_list):
    """L·∫•y c√°c ch·ªâ s·ªë t√†i ch√≠nh t·ª´ Yahoo Finance"""
    financial_data = []
    progress_bar = st.progress(0, text="ƒêang t·∫£i d·ªØ li·ªáu t·ª´ Yahoo Finance...")

    for idx, ticker_symbol in enumerate(tickers_list):
        try:
            ticker = yf.Ticker(ticker_symbol)
            info = ticker.info
            data = {
                'M√£ CP': ticker_symbol, 'Beta': info.get('beta'), 'P/E': info.get('trailingPE'),
                'N·ª£/V·ªën CSH': info.get('debtToEquity'), 'ROE': info.get('returnOnEquity'),
                'Bi√™n LN': info.get('profitMargins')
            }
            financial_data.append(data)
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu cho '{ticker_symbol}': {e}")
            financial_data.append({
                'M√£ CP': ticker_symbol, 'Beta': None, 'P/E': None, 'N·ª£/V·ªën CSH': None,
                'ROE': None, 'Bi√™n LN': None
            })
        progress_bar.progress((idx + 1) / len(tickers_list))

    progress_bar.empty()
    if not financial_data: return pd.DataFrame()

    df = pd.DataFrame(financial_data).set_index('M√£ CP')
    for col in df.columns:
        if df[col].isnull().all():
            st.error(f"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu cho c·ªôt '{col}'")
            return pd.DataFrame()
        if df[col].isnull().any():
            median_val = df[col].median()
            df[col] = df[col].fillna(median_val if pd.notna(median_val) else 0)
    return df

@st.cache_data
def get_data_from_db(_conn):
    """L·∫•y d·ªØ li·ªáu t·ª´ MySQL database"""
    if _conn and _conn.is_connected():
        try:
            return pd.read_sql("SELECT * FROM tickets_combined", _conn)
        except Exception as e:
            st.error(f"‚ùå L·ªói truy v·∫•n database: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

def run_topsis(decision_matrix, weights, impacts):
    """Thu·∫≠t to√°n TOPSIS"""
    norm_matrix = decision_matrix / np.sqrt((decision_matrix**2).sum(axis=0))
    weighted_matrix = norm_matrix * weights
    
    ideal_best = np.where(impacts == 1, weighted_matrix.max(axis=0), weighted_matrix.min(axis=0))
    ideal_worst = np.where(impacts == 1, weighted_matrix.min(axis=0), weighted_matrix.max(axis=0))

    dist_to_best = np.sqrt(((weighted_matrix - ideal_best)**2).sum(axis=1))
    dist_to_worst = np.sqrt(((weighted_matrix - ideal_worst)**2).sum(axis=1))
    
    epsilon = 1e-6
    return dist_to_worst / (dist_to_best + dist_to_worst + epsilon)

# --- GIAO DI·ªÜN CH√çNH ---
st.title("‚öñÔ∏è ·ª®ng d·ª•ng Ph√¢n t√≠ch R·ªßi ro ƒê·∫ßu t∆∞ C·ªï phi·∫øu b·∫±ng TOPSIS")
st.info("üéØ X·∫øp h·∫°ng r·ªßi ro c·ªï phi·∫øu d·ª±a tr√™n c√°c ch·ªâ s·ªë t√†i ch√≠nh v·ªõi tr·ªçng s·ªë t√πy ch·ªânh")

# --- SIDEBAR ---
with st.sidebar:
    st.header("‚öôÔ∏è B·∫£ng ƒëi·ªÅu khi·ªÉn")
    data_source = st.radio("üìÇ Ch·ªçn ngu·ªìn d·ªØ li·ªáu:", ["Yahoo Finance API", "Database MySQL"], key="data_source")

    weights = {}
    
    if data_source == "Yahoo Finance API":
        tickers_input = st.text_area("Nh·∫≠p m√£ c·ªï phi·∫øu (ph√¢n c√°ch b·ªüi d·∫•u ph·∫©y):", "AAPL, MSFT, GOOGL, TSLA, NVDA")
        
        criteria_yf = {'Beta': -1, 'P/E': -1, 'N·ª£/V·ªën CSH': -1, 'ROE': 1, 'Bi√™n LN': 1}
        st.header("‚öñÔ∏è Tr·ªçng s·ªë Ti√™u ch√≠")
        preset = st.selectbox("üéöÔ∏è Ch·ªçn b·ªô tr·ªçng s·ªë m·∫´u:", ["T√πy ch·ªânh", "An to√†n (Risk-averse)", "C√¢n b·∫±ng", "TƒÉng tr∆∞·ªüng"])

        if preset == "An to√†n (Risk-averse)": default_weights = {'Beta': 0.3, 'P/E': 0.2, 'N·ª£/V·ªën CSH': 0.3, 'ROE': 0.1, 'Bi√™n LN': 0.1}
        elif preset == "C√¢n b·∫±ng": default_weights = {'Beta': 0.2, 'P/E': 0.2, 'N·ª£/V·ªën CSH': 0.2, 'ROE': 0.2, 'Bi√™n LN': 0.2}
        elif preset == "TƒÉng tr∆∞·ªüng": default_weights = {'Beta': 0.1, 'P/E': 0.1, 'N·ª£/V·ªën CSH': 0.1, 'ROE': 0.35, 'Bi√™n LN': 0.35}
        else: default_weights = {k: 0.2 for k in criteria_yf.keys()}
        
        for crit, impact in criteria_yf.items():
            weights[crit] = st.slider(f"üéØ {crit}", 0.0, 1.0, default_weights.get(crit, 0.2), 0.05)
    
    elif data_source == "Database MySQL":
        st.header("‚öñÔ∏è Tr·ªçng s·ªë Ti√™u ch√≠")
        st.markdown("C√°c ch·ªâ s·ªë ph√¢n t√≠ch ƒë∆∞·ª£c l·∫•y m·∫∑c ƒë·ªãnh t·ª´ database.")
        default_weight = 1.0 / len(DB_CRITERIA)
        for crit in DB_CRITERIA:
            weights[crit] = st.slider(f"üéØ {crit} (*{DB_IMPACTS[crit]}*)", 0.0, 1.0, default_weight, 0.05, key=f'w_{crit}')
    
    # Ki·ªÉm tra t·ªïng tr·ªçng s·ªë
    total_weight = sum(weights.values())
    if abs(total_weight - 1.0) > 0.01:
        st.warning(f"‚ö†Ô∏è T·ªïng tr·ªçng s·ªë: {total_weight:.2f} (C·∫ßn = 1.0)")
    else:
        st.success(f"‚úÖ T·ªïng tr·ªçng s·ªë: {total_weight:.2f}")

    # === PH·∫¶N ƒê√É S·ª¨A: Hi·ªÉn th·ªã gi·∫£i th√≠ch t√πy theo ngu·ªìn d·ªØ li·ªáu ===
    with st.expander("‚ÑπÔ∏è Gi·∫£i th√≠ch c√°c ch·ªâ s·ªë"):
        if data_source == "Yahoo Finance API":
            st.markdown("""
            - **Beta**: ƒê·ªô bi·∫øn ƒë·ªông so v·ªõi th·ªã tr∆∞·ªùng (Cost: < 1 √≠t r·ªßi ro)
            - **P/E**: T·ª∑ l·ªá gi√°/thu nh·∫≠p (Cost: < 25 h·ª£p l√Ω)
            - **N·ª£/V·ªën CSH**: ƒê√≤n b·∫©y t√†i ch√≠nh (Cost: < 1 an to√†n)
            - **ROE**: L·ª£i nhu·∫≠n tr√™n v·ªën (Benefit: > 15% t·ªët)
            - **Bi√™n LN**: T·ª∑ su·∫•t l·ª£i nhu·∫≠n (Benefit: > 20% xu·∫•t s·∫Øc)
            """)
        else: # Database MySQL
            st.markdown("""
            - **RSI**: Ch·ªâ s·ªë s·ª©c m·∫°nh t∆∞∆°ng ƒë·ªëi (Cost: >70 l√† qu√° mua, r·ªßi ro)
            - **MACD**: T√≠n hi·ªáu xu h∆∞·ªõng (Benefit: >0 l√† xu h∆∞·ªõng tƒÉng)
            - **Trailing PE**: T·ª∑ l·ªá gi√°/thu nh·∫≠p (Cost: < 25 h·ª£p l√Ω)
            - **Market Cap**: V·ªën h√≥a th·ªã tr∆∞·ªùng (Benefit: C√†ng l·ªõn c√†ng ·ªïn ƒë·ªãnh)
            - **Returns**: L·ª£i nhu·∫≠n (Benefit: C√†ng cao c√†ng t·ªët)
            """)

# --- N√öT PH√ÇN T√çCH ---
if st.button("üöÄ B·∫Øt ƒë·∫ßu Ph√¢n t√≠ch", use_container_width=True):
    # Chu·∫©n h√≥a l·∫°i tr·ªçng s·ªë tr∆∞·ªõc khi ch·∫°y
    if sum(weights.values()) > 0:
        weights = {k: v / sum(weights.values()) for k, v in weights.items()}

    if data_source == "Yahoo Finance API":
        tickers_list = [t.strip().upper() for t in tickers_input.split(',') if t.strip()]
        if not tickers_list:
            st.error("‚ùå Vui l√≤ng nh·∫≠p √≠t nh·∫•t m·ªôt m√£ c·ªï phi·∫øu")
            st.stop()

        with st.spinner(f"‚è≥ ƒêang t·∫£i d·ªØ li·ªáu cho {len(tickers_list)} c·ªï phi·∫øu..."):
            raw_data = get_stock_data(tickers_list)
        
        criteria = criteria_yf
        col_impacts = {k: ('Benefit' if v == 1 else 'Cost') for k, v in criteria.items()}

    else: # Database MySQL Flow
        with st.spinner("‚è≥ ƒêang k·∫øt n·ªëi v√† x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ database..."):
            conn = get_db_connection()
            if not conn: st.stop()
            
            df_raw = get_data_from_db(conn)
            if df_raw.empty: st.stop()

            ticker_col = 'Ticker'
            if ticker_col not in df_raw.columns:
                st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt '{ticker_col}' trong database.")
                st.stop()

            if 'Date' in df_raw.columns:
                df_raw['Date'] = pd.to_datetime(df_raw['Date'], errors='coerce')
                df_grouped = df_raw.sort_values('Date', ascending=True).groupby(ticker_col).last().reset_index()
            else:
                df_grouped = df_raw.drop_duplicates(subset=[ticker_col], keep='last').reset_index(drop=True)
            
            missing_cols = [col for col in DB_CRITERIA if col not in df_grouped.columns]
            if missing_cols:
                st.error(f"‚ùå Database thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: **{', '.join(missing_cols)}**")
                st.stop()

            st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω **{len(df_grouped)}** m√£ c·ªï phi·∫øu v·ªõi {len(DB_CRITERIA)} ch·ªâ s·ªë m·∫∑c ƒë·ªãnh.")
        
        raw_data = df_grouped.set_index(ticker_col)[DB_CRITERIA].copy()
        raw_data.index.name = 'M√£ CP'

        for col in raw_data.columns:
            raw_data[col] = pd.to_numeric(raw_data[col], errors='coerce')
            if raw_data[col].isnull().any():
                median_val = raw_data[col].median()
                raw_data[col] = raw_data[col].fillna(median_val if pd.notna(median_val) else 0)

        criteria = {col: (1 if DB_IMPACTS[col] == 'Benefit' else -1) for col in DB_CRITERIA}
        col_impacts = DB_IMPACTS

    if raw_data.empty:
        st.error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch.")
        st.stop()

    # === PH·∫¶N X·ª¨ L√ù V√Ä HI·ªÇN TH·ªä K·∫æT QU·∫¢ CHUNG ===
    st.header("üìä D·ªØ li·ªáu ƒê·∫ßu v√†o sau khi x·ª≠ l√Ω")
    st.dataframe(raw_data.style.format("{:,.2f}").background_gradient(cmap='YlOrRd', axis=0), use_container_width=True)

    st.header("üèÜ K·∫øt qu·∫£ X·∫øp h·∫°ng TOPSIS")
    decision_matrix = raw_data[list(criteria.keys())]
    weights_list = np.array([weights[crit] for crit in criteria])
    impacts_list = np.array([criteria[crit] for crit in criteria])

    scores = run_topsis(decision_matrix, weights_list, impacts_list)

    results_df = raw_data.copy()
    results_df['ƒêi·ªÉm TOPSIS'] = scores
    results_df['X·∫øp h·∫°ng'] = results_df['ƒêi·ªÉm TOPSIS'].rank(ascending=False).astype(int)
    results_df = results_df.sort_values(by='X·∫øp h·∫°ng')
    
    col1, col2, col3 = st.columns(3)
    col1.metric("ü•á T·ªët nh·∫•t (√çt r·ªßi ro nh·∫•t)", results_df.index[0], f"{results_df['ƒêi·ªÉm TOPSIS'].iloc[0]:.4f}")
    col2.metric("ü•à R·ªßi ro nh·∫•t", results_df.index[-1], f"{results_df['ƒêi·ªÉm TOPSIS'].iloc[-1]:.4f}")
    col3.metric("üìä ƒêi·ªÉm trung b√¨nh", f"{results_df['ƒêi·ªÉm TOPSIS'].mean():.4f}")
    
    st.dataframe(
        results_df.style
        .apply(lambda row: ['background-color: #2E8B57; color: white; font-weight: bold' if row['X·∫øp h·∫°ng'] == 1 else '' for _ in row], axis=1)
        .background_gradient(cmap='Greens', subset=['ƒêi·ªÉm TOPSIS'])
        .format("{:.4f}", subset=raw_data.columns.tolist() + ['ƒêi·ªÉm TOPSIS']),
        use_container_width=True
    )

    tab1, tab2, tab3 = st.tabs(["üìä Bi·ªÉu ƒë·ªì So s√°nh", "üéØ Bi·ªÉu ƒë·ªì Radar", "üì• T·∫£i xu·ªëng"])
    with tab1:
        fig = px.bar(results_df, x=results_df.index, y='ƒêi·ªÉm TOPSIS', color='ƒêi·ªÉm TOPSIS',
                     color_continuous_scale='Greens', title='So s√°nh ƒêi·ªÉm TOPSIS gi·ªØa c√°c C·ªï phi·∫øu', text='ƒêi·ªÉm TOPSIS')
        fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')
        fig.update_layout(xaxis_title="M√£ C·ªï phi·∫øu", yaxis_title="ƒêi·ªÉm TOPSIS", xaxis={'categoryorder':'total descending'})
        st.plotly_chart(fig, use_container_width=True)
    with tab2:
        top_n = min(5, len(results_df))
        top_stocks = results_df.head(top_n)
        norm_data = (top_stocks[list(criteria.keys())] - top_stocks[list(criteria.keys())].min()) / \
                    (top_stocks[list(criteria.keys())].max() - top_stocks[list(criteria.keys())].min())
        fig = go.Figure()
        for ticker in top_stocks.index:
            fig.add_trace(go.Scatterpolar(r=norm_data.loc[ticker].values, theta=list(criteria.keys()), fill='toself', name=ticker))
        fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 1])), showlegend=True, title=f"So s√°nh Top {top_n} C·ªï phi·∫øu (d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a)")
        st.plotly_chart(fig, use_container_width=True)
    with tab3:
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            results_df.to_excel(writer, sheet_name='Ket_qua_TOPSIS')
            raw_data.to_excel(writer, sheet_name='Du_lieu_goc')
            pd.DataFrame({
                'Ch·ªâ s·ªë': list(weights.keys()),
                'Tr·ªçng s·ªë': list(weights.values()),
                'T√°c ƒë·ªông': [col_impacts[k] for k in weights.keys()]
            }).to_excel(writer, sheet_name='Cau_hinh_phan_tich', index=False)
        
        st.download_button("üìä T·∫£i b√°o c√°o chi ti·∫øt (.xlsx)", output.getvalue(),
                          f"topsis_report_{datetime.now().strftime('%Y%m%d')}.xlsx",
                          "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)

st.markdown("---")
st.markdown("üî¨ **TOPSIS Analysis System**")