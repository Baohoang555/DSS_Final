import mysql.connector
from mysql.connector import Error
import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
from datetime import datetime

# --- Cáº¤U HÃŒNH TRANG WEB ---
st.set_page_config(
    page_title="TOPSIS - PhÃ¢n tÃ­ch Rá»§i ro Cá»• phiáº¿u",
    page_icon="âš–ï¸",
    layout="wide"
)

# --- CÃC BIáº¾N Cá» Äá»ŠNH CHO LUá»’NG DATABASE ---
DB_CRITERIA = ['RSI', 'MACD', 'trailingPE_snapshot', 'marketCap_snapshot', 'Returns']
DB_IMPACTS = {
    'RSI': 'Cost',
    'MACD': 'Benefit',
    'trailingPE_snapshot': 'Cost',
    'marketCap_snapshot': 'Benefit',
    'Returns': 'Benefit'
}

# === PHáº¦N Má»šI: ThÃªm dictionary giáº£i thÃ­ch cÃ¡c chá»‰ sá»‘ ===
CRITERIA_EXPLANATIONS = {
    # Yahoo Finance
    'Beta': "Äo lÆ°á»ng má»©c Ä‘á»™ biáº¿n Ä‘á»™ng cá»§a cá»• phiáº¿u so vá»›i thá»‹ trÆ°á»ng chung. Beta < 1 cho tháº¥y Ã­t biáº¿n Ä‘á»™ng hÆ¡n thá»‹ trÆ°á»ng (Ã­t rá»§i ro hÆ¡n).",
    'P/E': "Tá»· lá»‡ GiÃ¡ trÃªn Thu nháº­p. Chá»‰ sá»‘ nÃ y cho biáº¿t nhÃ  Ä‘áº§u tÆ° sáºµn sÃ ng tráº£ bao nhiÃªu cho má»™t Ä‘á»“ng lá»£i nhuáº­n. P/E quÃ¡ cao cÃ³ thá»ƒ lÃ  dáº¥u hiá»‡u Ä‘á»‹nh giÃ¡ Ä‘áº¯t.",
    'Ná»£/Vá»‘n CSH': "Tá»· lá»‡ Ná»£ trÃªn Vá»‘n chá»§ sá»Ÿ há»¯u, Ä‘o lÆ°á»ng Ä‘Ã²n báº©y tÃ i chÃ­nh. Tá»· lá»‡ < 1 thÆ°á»ng Ä‘Æ°á»£c coi lÃ  an toÃ n.",
    'ROE': "Lá»£i nhuáº­n trÃªn Vá»‘n chá»§ sá»Ÿ há»¯u. Äo lÆ°á»ng kháº£ nÄƒng sinh lá»i cá»§a cÃ´ng ty. ROE > 15% thÆ°á»ng Ä‘Æ°á»£c xem lÃ  tá»‘t.",
    'BiÃªn LN': "BiÃªn Lá»£i nhuáº­n. Cho biáº¿t cÃ´ng ty táº¡o ra bao nhiÃªu lá»£i nhuáº­n tá»« doanh thu. BiÃªn lá»£i nhuáº­n cÃ ng cao cÃ ng tá»‘t.",
    # Database
    'RSI': "Chá»‰ sá»‘ Sá»©c máº¡nh TÆ°Æ¡ng Ä‘á»‘i. Äo lÆ°á»ng tá»‘c Ä‘á»™ vÃ  sá»± thay Ä‘á»•i cá»§a cÃ¡c biáº¿n Ä‘á»™ng giÃ¡. RSI > 70 cho tháº¥y tÃ­n hiá»‡u 'quÃ¡ mua' (cÃ³ thá»ƒ sá»›m Ä‘iá»u chá»‰nh giáº£m).",
    'MACD': "ÄÆ°á»ng Trung bÃ¬nh Ä‘á»™ng há»™i tá»¥/phÃ¢n ká»³. LÃ  má»™t chá»‰ bÃ¡o xu hÆ°á»›ng. MACD > 0 thÆ°á»ng bÃ¡o hiá»‡u xu hÆ°á»›ng tÄƒng.",
    'trailingPE_snapshot': "TÆ°Æ¡ng tá»± P/E, tá»· lá»‡ giÃ¡ trÃªn thu nháº­p trong 12 thÃ¡ng gáº§n nháº¥t.",
    'marketCap_snapshot': "Vá»‘n hÃ³a thá»‹ trÆ°á»ng. CÃ¡c cÃ´ng ty cÃ³ vá»‘n hÃ³a lá»›n thÆ°á»ng á»•n Ä‘á»‹nh vÃ  Ã­t rá»§i ro hÆ¡n.",
    'Returns': "Tá»· suáº¥t lá»£i nhuáº­n cá»§a cá»• phiáº¿u trong má»™t khoáº£ng thá»i gian."
}


# --- HÃ€M Káº¾T Ná»I DATABASE ---
@st.cache_resource
def get_db_connection():
    """Táº¡o káº¿t ná»‘i tá»›i MySQL database"""
    try:
        connection = mysql.connector.connect(
            host='127.0.0.1',
            user='root',
            password='130225',
            database='tickets',
            port=3306
        )
        return connection
    except Error as e:
        st.error(f"âŒ Lá»—i káº¿t ná»‘i database: {e}")
        return None

# --- HÃ€M Láº¤Y Dá»® LIá»†U ---
@st.cache_data
def get_stock_data(tickers_list):
    """Láº¥y cÃ¡c chá»‰ sá»‘ tÃ i chÃ­nh tá»« Yahoo Finance"""
    financial_data = []
    progress_bar = st.progress(0, text="Äang táº£i dá»¯ liá»‡u tá»« Yahoo Finance...")

    for idx, ticker_symbol in enumerate(tickers_list):
        try:
            ticker = yf.Ticker(ticker_symbol)
            info = ticker.info
            data = {
                'MÃ£ CP': ticker_symbol, 'Beta': info.get('beta'), 'P/E': info.get('trailingPE'),
                'Ná»£/Vá»‘n CSH': info.get('debtToEquity'), 'ROE': info.get('returnOnEquity'),
                'BiÃªn LN': info.get('profitMargins')
            }
            financial_data.append(data)
        except Exception as e:
            st.warning(f"âš ï¸ KhÃ´ng thá»ƒ láº¥y dá»¯ liá»‡u cho '{ticker_symbol}': {e}")
            financial_data.append({
                'MÃ£ CP': ticker_symbol, 'Beta': None, 'P/E': None, 'Ná»£/Vá»‘n CSH': None,
                'ROE': None, 'BiÃªn LN': None
            })
        progress_bar.progress((idx + 1) / len(tickers_list))

    progress_bar.empty()
    if not financial_data: return pd.DataFrame()

    df = pd.DataFrame(financial_data).set_index('MÃ£ CP')
    for col in df.columns:
        if df[col].isnull().all():
            st.error(f"âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u cho cá»™t '{col}'")
            return pd.DataFrame()
        if df[col].isnull().any():
            median_val = df[col].median()
            df[col] = df[col].fillna(median_val if pd.notna(median_val) else 0)
    return df

@st.cache_data
def get_data_from_db(_conn):
    """Láº¥y dá»¯ liá»‡u tá»« MySQL database"""
    if _conn and _conn.is_connected():
        try:
            return pd.read_sql("SELECT * FROM tickets_combined", _conn)
        except Exception as e:
            st.error(f"âŒ Lá»—i truy váº¥n database: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

def run_topsis(decision_matrix, weights, impacts):
    """Thuáº­t toÃ¡n TOPSIS"""
    norm_matrix = decision_matrix / np.sqrt((decision_matrix**2).sum(axis=0))
    weighted_matrix = norm_matrix * weights
    
    ideal_best = np.where(impacts == 1, weighted_matrix.max(axis=0), weighted_matrix.min(axis=0))
    ideal_worst = np.where(impacts == 1, weighted_matrix.min(axis=0), weighted_matrix.max(axis=0))

    dist_to_best = np.sqrt(((weighted_matrix - ideal_best)**2).sum(axis=1))
    dist_to_worst = np.sqrt(((weighted_matrix - ideal_worst)**2).sum(axis=1))
    
    epsilon = 1e-6
    return dist_to_worst / (dist_to_best + dist_to_worst + epsilon)

# === PHáº¦N Má»šI: HÃ m táº¡o nháº­n xÃ©t vÃ  gá»£i Ã½ ===
def generate_analysis_text(results_df, weights, impacts):
    """Táº¡o ra cÃ¡c Ä‘oáº¡n vÄƒn báº£n phÃ¢n tÃ­ch vÃ  gá»£i Ã½"""
    best_stock_name = results_df.index[0]
    worst_stock_name = results_df.index[-1]
    best_stock_data = results_df.iloc[0]
    worst_stock_data = results_df.iloc[-1]

    # PhÃ¢n tÃ­ch cá»• phiáº¿u tá»‘t nháº¥t
    best_reasons = []
    for crit, impact in impacts.items():
        val = best_stock_data[crit]
        # TÃ¬m cÃ¡c yáº¿u tá»‘ ná»•i báº­t (vÃ­ dá»¥: top 25% tá»‘t nháº¥t)
        if (impact == 'Benefit' and val >= results_df[crit].quantile(0.75)) or \
           (impact == 'Cost' and val <= results_df[crit].quantile(0.25)):
            best_reasons.append(f"**{crit}** ({val:.2f})")

    best_analysis = f"ğŸ† **{best_stock_name}** Ä‘Æ°á»£c xáº¿p háº¡ng cao nháº¥t. Äiá»ƒm máº¡nh chÃ­nh Ä‘áº¿n tá»« cÃ¡c chá»‰ sá»‘: {', '.join(best_reasons[:3])}."
    
    # PhÃ¢n tÃ­ch cá»• phiáº¿u rá»§i ro nháº¥t
    worst_reasons = []
    for crit, impact in impacts.items():
        val = worst_stock_data[crit]
        if (impact == 'Benefit' and val <= results_df[crit].quantile(0.25)) or \
           (impact == 'Cost' and val >= results_df[crit].quantile(0.75)):
            worst_reasons.append(f"**{crit}** ({val:.2f})")
    
    worst_analysis = f"âš ï¸ **{worst_stock_name}** cÃ³ rá»§i ro cao nháº¥t trong danh sÃ¡ch, chá»§ yáº¿u do cÃ¡c chá»‰ sá»‘ chÆ°a tá»‘t nhÆ°: {', '.join(worst_reasons[:3])}."

    # Gá»£i Ã½ hÃ nh Ä‘á»™ng
    actionable_advice = """
    ğŸ’¡ **Gá»£i Ã½ hÃ nh Ä‘á»™ng:**
    - **Äá»‘i vá»›i cÃ¡c cá»• phiáº¿u top Ä‘áº§u:** ÄÃ¢y lÃ  nhá»¯ng á»©ng viÃªn sÃ¡ng giÃ¡ dá»±a trÃªn tiÃªu chÃ­ cá»§a báº¡n. HÃ£y cÃ¢n nháº¯c Ä‘Æ°a vÃ o danh sÃ¡ch theo dÃµi vÃ  **phÃ¢n tÃ­ch sÃ¢u hÆ¡n** vá» yáº¿u tá»‘ cÆ¡ báº£n cá»§a doanh nghiá»‡p trÆ°á»›c khi Ä‘áº§u tÆ°.
    - **Äá»‘i vá»›i cÃ¡c cá»• phiáº¿u cuá»‘i báº£ng:** Cáº§n tháº­n trá»ng vá»›i cÃ¡c cá»• phiáº¿u nÃ y. Náº¿u Ä‘ang náº¯m giá»¯, báº¡n nÃªn **xem xÃ©t láº¡i vá»‹ tháº¿** vÃ  cÃ³ thá»ƒ Ä‘áº·t cÃ¡c biá»‡n phÃ¡p phÃ²ng ngá»«a rá»§i ro nhÆ° **lá»‡nh cáº¯t lá»— (stop-loss)**.
    - **LÆ°u Ã½:** Káº¿t quáº£ nÃ y hoÃ n toÃ n dá»±a trÃªn cÃ¡c chá»‰ sá»‘ vÃ  trá»ng sá»‘ báº¡n Ä‘Ã£ cung cáº¥p. ÄÃ¢y lÃ  cÃ´ng cá»¥ tham kháº£o, khÃ´ng pháº£i lá»i khuyÃªn Ä‘áº§u tÆ° trá»±c tiáº¿p.
    """
    
    return best_analysis, worst_analysis, actionable_advice

# === PHáº¦N Má»šI: HÃ m Ä‘á»‹nh dáº¡ng sá»‘ lá»›n ===
def format_large_number(num):
    """Äá»‹nh dáº¡ng sá»‘ lá»›n (vd: vá»‘n hÃ³a) thÃ nh dáº¡ng tá»·, triá»‡u."""
    if pd.isna(num):
        return "N/A"
    num = float(num)
    if num >= 1e12:
        return f"{num / 1e12:.2f} nghÃ¬n tá»·"
    if num >= 1e9:
        return f"{num / 1e9:.2f} tá»·"
    if num >= 1e6:
        return f"{num / 1e6:.2f} triá»‡u"
    return f"{num:,.2f}"

# --- GIAO DIá»†N CHÃNH ---
st.title("âš–ï¸ á»¨ng dá»¥ng PhÃ¢n tÃ­ch Rá»§i ro Äáº§u tÆ° Cá»• phiáº¿u báº±ng TOPSIS")
st.info("ğŸ¯ Xáº¿p háº¡ng rá»§i ro cá»• phiáº¿u dá»±a trÃªn cÃ¡c chá»‰ sá»‘ tÃ i chÃ­nh vá»›i trá»ng sá»‘ tÃ¹y chá»‰nh")

# --- SIDEBAR ---
with st.sidebar:
    st.header("âš™ï¸ Báº£ng Ä‘iá»u khiá»ƒn")
    data_source = st.radio("ğŸ“‚ Chá»n nguá»“n dá»¯ liá»‡u:", ["Yahoo Finance API", "Database MySQL"], key="data_source")

    weights = {}
    
    if data_source == "Yahoo Finance API":
        tickers_input = st.text_area("Nháº­p mÃ£ cá»• phiáº¿u (phÃ¢n cÃ¡ch bá»Ÿi dáº¥u pháº©y):", "AAPL, MSFT, GOOGL, TSLA, NVDA")
        
        criteria_yf = {'Beta': -1, 'P/E': -1, 'Ná»£/Vá»‘n CSH': -1, 'ROE': 1, 'BiÃªn LN': 1}
        st.header("âš–ï¸ Trá»ng sá»‘ TiÃªu chÃ­")
        preset = st.selectbox("ğŸšï¸ Chá»n bá»™ trá»ng sá»‘ máº«u:", ["TÃ¹y chá»‰nh", "An toÃ n (Risk-averse)", "CÃ¢n báº±ng", "TÄƒng trÆ°á»Ÿng"])

        if preset == "An toÃ n (Risk-averse)": default_weights = {'Beta': 0.3, 'P/E': 0.2, 'Ná»£/Vá»‘n CSH': 0.3, 'ROE': 0.1, 'BiÃªn LN': 0.1}
        elif preset == "CÃ¢n báº±ng": default_weights = {'Beta': 0.2, 'P/E': 0.2, 'Ná»£/Vá»‘n CSH': 0.2, 'ROE': 0.2, 'BiÃªn LN': 0.2}
        elif preset == "TÄƒng trÆ°á»Ÿng": default_weights = {'Beta': 0.1, 'P/E': 0.1, 'Ná»£/Vá»‘n CSH': 0.1, 'ROE': 0.35, 'BiÃªn LN': 0.35}
        else: default_weights = {k: 0.2 for k in criteria_yf.keys()}
        
        # === PHáº¦N Sá»¬A Äá»”I: ThÃªm help tooltip vÃ o slider ===
        for crit, impact in criteria_yf.items():
            weights[crit] = st.slider(
                f"ğŸ¯ {crit}", 0.0, 1.0, default_weights.get(crit, 0.2), 0.05,
                help=CRITERIA_EXPLANATIONS.get(crit, "ChÆ°a cÃ³ giáº£i thÃ­ch")
            )
    
    elif data_source == "Database MySQL":
        st.header("âš–ï¸ Trá»ng sá»‘ TiÃªu chÃ­")
        st.markdown("CÃ¡c chá»‰ sá»‘ phÃ¢n tÃ­ch Ä‘Æ°á»£c láº¥y máº·c Ä‘á»‹nh tá»« database.")
        default_weight = 1.0 / len(DB_CRITERIA)
        # === PHáº¦N Sá»¬A Äá»”I: ThÃªm help tooltip vÃ o slider ===
        for crit in DB_CRITERIA:
            weights[crit] = st.slider(
                f"ğŸ¯ {crit} (*{DB_IMPACTS[crit]}*)", 0.0, 1.0, default_weight, 0.05,
                key=f'w_{crit}',
                help=CRITERIA_EXPLANATIONS.get(crit, "ChÆ°a cÃ³ giáº£i thÃ­ch")
            )
    
    # Kiá»ƒm tra tá»•ng trá»ng sá»‘
    total_weight = sum(weights.values())
    if abs(total_weight - 1.0) > 0.01:
        st.warning(f"âš ï¸ Tá»•ng trá»ng sá»‘: {total_weight:.2f} (Cáº§n = 1.0)")
    else:
        st.success(f"âœ… Tá»•ng trá»ng sá»‘: {total_weight:.2f}")

# --- NÃšT PHÃ‚N TÃCH ---
if st.button("ğŸš€ Báº¯t Ä‘áº§u PhÃ¢n tÃ­ch", use_container_width=True):
    # Chuáº©n hÃ³a láº¡i trá»ng sá»‘ trÆ°á»›c khi cháº¡y
    if sum(weights.values()) > 0:
        weights = {k: v / sum(weights.values()) for k, v in weights.items()}

    if data_source == "Yahoo Finance API":
        tickers_list = [t.strip().upper() for t in tickers_input.split(',') if t.strip()]
        if not tickers_list:
            st.error("âŒ Vui lÃ²ng nháº­p Ã­t nháº¥t má»™t mÃ£ cá»• phiáº¿u")
            st.stop()

        with st.spinner(f"â³ Äang táº£i dá»¯ liá»‡u cho {len(tickers_list)} cá»• phiáº¿u..."):
            raw_data = get_stock_data(tickers_list)
        
        criteria = criteria_yf
        col_impacts = {k: ('Benefit' if v == 1 else 'Cost') for k, v in criteria.items()}

    else: # Database MySQL Flow
        with st.spinner("â³ Äang káº¿t ná»‘i vÃ  xá»­ lÃ½ dá»¯ liá»‡u tá»« database..."):
            conn = get_db_connection()
            if not conn: st.stop()
            
            df_raw = get_data_from_db(conn)
            if df_raw.empty: st.stop()

            ticker_col = 'Ticker'
            if ticker_col not in df_raw.columns:
                st.error(f"âŒ KhÃ´ng tÃ¬m tháº¥y cá»™t '{ticker_col}' trong database.")
                st.stop()

            if 'Date' in df_raw.columns:
                df_raw['Date'] = pd.to_datetime(df_raw['Date'], errors='coerce')
                df_grouped = df_raw.sort_values('Date', ascending=True).groupby(ticker_col).last().reset_index()
            else:
                df_grouped = df_raw.drop_duplicates(subset=[ticker_col], keep='last').reset_index(drop=True)
            
            missing_cols = [col for col in DB_CRITERIA if col not in df_grouped.columns]
            if missing_cols:
                st.error(f"âŒ Database thiáº¿u cÃ¡c cá»™t báº¯t buá»™c: **{', '.join(missing_cols)}**")
                st.stop()

            st.success(f"âœ… ÄÃ£ xá»­ lÃ½ **{len(df_grouped)}** mÃ£ cá»• phiáº¿u vá»›i {len(DB_CRITERIA)} chá»‰ sá»‘ máº·c Ä‘á»‹nh.")
        
        raw_data = df_grouped.set_index(ticker_col)[DB_CRITERIA].copy()
        raw_data.index.name = 'MÃ£ CP'

        for col in raw_data.columns:
            raw_data[col] = pd.to_numeric(raw_data[col], errors='coerce')
            if raw_data[col].isnull().any():
                median_val = raw_data[col].median()
                raw_data[col] = raw_data[col].fillna(median_val if pd.notna(median_val) else 0)

        criteria = {col: (1 if DB_IMPACTS[col] == 'Benefit' else -1) for col in DB_CRITERIA}
        col_impacts = DB_IMPACTS

    if raw_data.empty:
        st.error("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ phÃ¢n tÃ­ch.")
        st.stop()

    # === PHáº¦N Sá»¬A Äá»”I: Ãp dá»¥ng Ä‘á»‹nh dáº¡ng sá»‘ lá»›n cho báº£ng dá»¯ liá»‡u Ä‘áº§u vÃ o ===
    st.header("ğŸ“Š Dá»¯ liá»‡u Äáº§u vÃ o sau khi xá»­ lÃ½")
    formatters = {col: "{:,.2f}" for col in raw_data.columns}
    if 'marketCap_snapshot' in raw_data.columns:
        formatters['marketCap_snapshot'] = format_large_number
    st.dataframe(raw_data.style.format(formatters).background_gradient(cmap='YlOrRd', axis=0), use_container_width=True)

    st.header("ğŸ† Káº¿t quáº£ Xáº¿p háº¡ng TOPSIS")
    decision_matrix = raw_data[list(criteria.keys())]
    weights_list = np.array([weights[crit] for crit in criteria])
    impacts_list = np.array([criteria[crit] for crit in criteria])

    scores = run_topsis(decision_matrix, weights_list, impacts_list)

    results_df = raw_data.copy()
    results_df['Äiá»ƒm TOPSIS'] = scores
    results_df['Xáº¿p háº¡ng'] = results_df['Äiá»ƒm TOPSIS'].rank(ascending=False).astype(int)
    results_df = results_df.sort_values(by='Xáº¿p háº¡ng')
    
    col1, col2, col3 = st.columns(3)
    col1.metric("ğŸ¥‡ Tá»‘t nháº¥t (Ãt rá»§i ro nháº¥t)", results_df.index[0], f"{results_df['Äiá»ƒm TOPSIS'].iloc[0]:.4f}")
    col2.metric("ğŸ¥ˆ Rá»§i ro nháº¥t", results_df.index[-1], f"{results_df['Äiá»ƒm TOPSIS'].iloc[-1]:.4f}")
    col3.metric("ğŸ“Š Äiá»ƒm trung bÃ¬nh", f"{results_df['Äiá»ƒm TOPSIS'].mean():.4f}")
    
    # === PHáº¦N Sá»¬A Äá»”I: Ãp dá»¥ng Ä‘á»‹nh dáº¡ng sá»‘ lá»›n cho báº£ng káº¿t quáº£ ===
    result_formatters = {col: "{:,.4f}" for col in raw_data.columns}
    result_formatters['Äiá»ƒm TOPSIS'] = "{:.4f}"
    if 'marketCap_snapshot' in results_df.columns:
        result_formatters['marketCap_snapshot'] = format_large_number

    st.dataframe(
        results_df.style
        .apply(lambda row: ['background-color: #2E8B57; color: white; font-weight: bold' if row['Xáº¿p háº¡ng'] == 1 else '' for _ in row], axis=1)
        .background_gradient(cmap='Greens', subset=['Äiá»ƒm TOPSIS'])
        .format(result_formatters),
        use_container_width=True
    )
    
    # === PHáº¦N Má»šI: Hiá»ƒn thá»‹ phÃ¢n tÃ­ch vÃ  gá»£i Ã½ ===
    st.markdown("---")
    st.subheader("ğŸ“ PhÃ¢n tÃ­ch vÃ  Gá»£i Ã½ tá»« Há»‡ thá»‘ng")
    best_analysis, worst_analysis, actionable_advice = generate_analysis_text(results_df, weights, col_impacts)
    st.markdown(best_analysis)
    st.markdown(worst_analysis)
    st.markdown(actionable_advice)
    st.markdown("---")


    tab1, tab2, tab3 = st.tabs(["ğŸ“Š Biá»ƒu Ä‘á»“ So sÃ¡nh", "ğŸ¯ Biá»ƒu Ä‘á»“ Radar", "ğŸ“¥ Táº£i xuá»‘ng"])
    with tab1:
        fig = px.bar(results_df, x=results_df.index, y='Äiá»ƒm TOPSIS', color='Äiá»ƒm TOPSIS',
                     color_continuous_scale='Greens', title='So sÃ¡nh Äiá»ƒm TOPSIS giá»¯a cÃ¡c Cá»• phiáº¿u', text='Äiá»ƒm TOPSIS')
        fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')
        fig.update_layout(xaxis_title="MÃ£ Cá»• phiáº¿u", yaxis_title="Äiá»ƒm TOPSIS", xaxis={'categoryorder':'total descending'})
        st.plotly_chart(fig, use_container_width=True)
    with tab2:
        top_n = min(5, len(results_df))
        top_stocks = results_df.head(top_n)
        norm_data = (top_stocks[list(criteria.keys())] - top_stocks[list(criteria.keys())].min()) / \
                    (top_stocks[list(criteria.keys())].max() - top_stocks[list(criteria.keys())].min())
        fig = go.Figure()
        for ticker in top_stocks.index:
            fig.add_trace(go.Scatterpolar(r=norm_data.loc[ticker].values, theta=list(criteria.keys()), fill='toself', name=ticker))
        fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 1])), showlegend=True, title=f"So sÃ¡nh Top {top_n} Cá»• phiáº¿u (dá»¯ liá»‡u Ä‘Ã£ chuáº©n hÃ³a)")
        st.plotly_chart(fig, use_container_width=True)
    with tab3:
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            results_df.to_excel(writer, sheet_name='Ket_qua_TOPSIS')
            raw_data.to_excel(writer, sheet_name='Du_lieu_goc')
            pd.DataFrame({
                'Chá»‰ sá»‘': list(weights.keys()),
                'Trá»ng sá»‘': list(weights.values()),
                'TÃ¡c Ä‘á»™ng': [col_impacts[k] for k in weights.keys()]
            }).to_excel(writer, sheet_name='Cau_hinh_phan_tich', index=False)
        
        st.download_button("ğŸ“Š Táº£i bÃ¡o cÃ¡o chi tiáº¿t (.xlsx)", output.getvalue(),
                          f"topsis_report_{datetime.now().strftime('%Y%m%d')}.xlsx",
                          "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)

st.markdown("---")
st.markdown("ğŸ”¬ **TOPSIS Analysis System**")