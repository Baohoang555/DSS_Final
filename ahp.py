import mysql.connector
from mysql.connector import Error
import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
from datetime import datetime
import itertools # ThÆ° viá»‡n Ä‘á»ƒ táº¡o cÃ¡c cáº·p so sÃ¡nh cho AHP
import scipy
from scipy.stats import spearmanr

# --- Cáº¤U HÃŒNH TRANG WEB ---
st.set_page_config(
    page_title="TOPSIS & AHP - PhÃ¢n tÃ­ch Rá»§i ro Cá»• phiáº¿u",
    page_icon="âš–ï¸",
    layout="wide"
)

# --- CÃC BIáº¾N Cá» Äá»ŠNH CHO LUá»’NG DATABASE ---
DB_CRITERIA = ['RSI', 'MACD', 'trailingPE_snapshot', 'marketCap_snapshot', 'Returns']
DB_IMPACTS = {
    'RSI': 'Cost',
    'MACD': 'Benefit',
    'trailingPE_snapshot': 'Cost',
    'marketCap_snapshot': 'Benefit',
    'Returns': 'Benefit'
}

# === DICTIONARY GIáº¢I THÃCH CÃC CHá»ˆ Sá» ===
CRITERIA_EXPLANATIONS = {
    # Yahoo Finance
    'Beta': "Äo lÆ°á»ng má»©c Ä‘á»™ biáº¿n Ä‘á»™ng cá»§a cá»• phiáº¿u so vá»›i thá»‹ trÆ°á»ng chung. Beta < 1 cho tháº¥y Ã­t biáº¿n Ä‘á»™ng hÆ¡n thá»‹ trÆ°á»ng (Ã­t rá»§i ro hÆ¡n).",
    'P/E': "Tá»· lá»‡ GiÃ¡ trÃªn Thu nháº­p. Chá»‰ sá»‘ nÃ y cho biáº¿t nhÃ  Ä‘áº§u tÆ° sáºµn sÃ ng tráº£ bao nhiÃªu cho má»™t Ä‘á»“ng lá»£i nhuáº­n. P/E quÃ¡ cao cÃ³ thá»ƒ lÃ  dáº¥u hiá»‡u Ä‘á»‹nh giÃ¡ Ä‘áº¯t.",
    'Ná»£/Vá»‘n CSH': "Tá»· lá»‡ Ná»£ trÃªn Vá»‘n chá»§ sá»Ÿ há»¯u, Ä‘o lÆ°á»ng Ä‘Ã²n báº©y tÃ i chÃ­nh. Tá»· lá»‡ < 1 thÆ°á»ng Ä‘Æ°á»£c coi lÃ  an toÃ n.",
    'ROE': "Lá»£i nhuáº­n trÃªn Vá»‘n chá»§ sá»Ÿ há»¯u. Äo lÆ°á»ng kháº£ nÄƒng sinh lá»i cá»§a cÃ´ng ty. ROE > 15% thÆ°á»ng Ä‘Æ°á»£c xem lÃ  tá»‘t.",
    'BiÃªn LN': "BiÃªn Lá»£i nhuáº­n. Cho biáº¿t cÃ´ng ty táº¡o ra bao nhiÃªu lá»£i nhuáº­n tá»« doanh thu. BiÃªn lá»£i nhuáº­n cÃ ng cao cÃ ng tá»‘t.",
    # Database
    'RSI': "Chá»‰ sá»‘ Sá»©c máº¡nh TÆ°Æ¡ng Ä‘á»‘i. Äo lÆ°á»ng tá»‘c Ä‘á»™ vÃ  sá»± thay Ä‘á»•i cá»§a cÃ¡c biáº¿n Ä‘á»™ng giÃ¡. RSI > 70 cho tháº¥y tÃ­n hiá»‡u 'quÃ¡ mua' (cÃ³ thá»ƒ sá»›m Ä‘iá»u chá»‰nh giáº£m).",
    'MACD': "ÄÆ°á»ng Trung bÃ¬nh Ä‘á»™ng há»™i tá»¥/phÃ¢n ká»³. LÃ  má»™t chá»‰ bÃ¡o xu hÆ°á»›ng. MACD > 0 thÆ°á»ng bÃ¡o hiá»‡u xu hÆ°á»›ng tÄƒng.",
    'trailingPE_snapshot': "TÆ°Æ¡ng tá»± P/E, tá»· lá»‡ giÃ¡ trÃªn thu nháº­p trong 12 thÃ¡ng gáº§n nháº¥t.",
    'marketCap_snapshot': "Vá»‘n hÃ³a thá»‹ trÆ°á»ng. CÃ¡c cÃ´ng ty cÃ³ vá»‘n hÃ³a lá»›n thÆ°á»ng á»•n Ä‘á»‹nh vÃ  Ã­t rá»§i ro hÆ¡n.",
    'Returns': "Tá»· suáº¥t lá»£i nhuáº­n cá»§a cá»• phiáº¿u trong má»™t khoáº£ng thá»i gian."
}

# --- HÃ€M Káº¾T Ná»I DATABASE ---
@st.cache_resource
def get_db_connection():
    """Táº¡o káº¿t ná»‘i tá»›i MySQL database"""
    try:
        connection = mysql.connector.connect(
            host='127.0.0.1',
            user='root',
            password='130225',      # <-- THAY Äá»”I Máº¬T KHáº¨U Cá»¦A Báº N Táº I ÄÃ‚Y
            database='tickets',    # <-- THAY Äá»”I TÃŠN DATABASE Cá»¦A Báº N Táº I ÄÃ‚Y
            port=3306
        )
        return connection
    except Error as e:
        st.error(f"âŒ Lá»—i káº¿t ná»‘i database: {e}")
        return None

# --- HÃ€M Láº¤Y Dá»® LIá»†U ---
@st.cache_data
def get_stock_data(tickers_list):
    """Láº¥y cÃ¡c chá»‰ sá»‘ tÃ i chÃ­nh tá»« Yahoo Finance"""
    financial_data = []
    progress_bar = st.progress(0, text="Äang táº£i dá»¯ liá»‡u tá»« Yahoo Finance...")

    for idx, ticker_symbol in enumerate(tickers_list):
        try:
            ticker = yf.Ticker(ticker_symbol)
            info = ticker.info
            data = {
                'MÃ£ CP': ticker_symbol, 'Beta': info.get('beta'), 'P/E': info.get('trailingPE'),
                'Ná»£/Vá»‘n CSH': info.get('debtToEquity'), 'ROE': info.get('returnOnEquity'),
                'BiÃªn LN': info.get('profitMargins')
            }
            financial_data.append(data)
        except Exception as e:
            st.warning(f"âš ï¸ KhÃ´ng thá»ƒ láº¥y dá»¯ liá»‡u cho '{ticker_symbol}'.")
            financial_data.append({
                'MÃ£ CP': ticker_symbol, 'Beta': None, 'P/E': None, 'Ná»£/Vá»‘n CSH': None,
                'ROE': None, 'BiÃªn LN': None
            })
        progress_bar.progress((idx + 1) / len(tickers_list))

    progress_bar.empty()
    if not financial_data: return pd.DataFrame()

    df = pd.DataFrame(financial_data).set_index('MÃ£ CP')
    for col in df.columns:
        if df[col].isnull().all():
            st.error(f"âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u cho cá»™t '{col}'")
            return pd.DataFrame()
        if df[col].isnull().any():
            median_val = df[col].median()
            df[col] = df[col].fillna(median_val if pd.notna(median_val) else 0)
    return df

@st.cache_data
def get_data_from_db(_conn):
    """Láº¥y dá»¯ liá»‡u tá»« MySQL database"""
    if _conn and _conn.is_connected():
        try:
            # <-- THAY Äá»”I TÃŠN Báº¢NG Cá»¦A Báº N Táº I ÄÃ‚Y
            return pd.read_sql("SELECT * FROM tickets_combined", _conn)
        except Exception as e:
            st.error(f"âŒ Lá»—i truy váº¥n database: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

# === HÃ€M TÃNH TOÃN Cá»¦A AHP VÃ€ TOPSIS ===
def calculate_ahp_weights(comparison_matrix):
    """TÃ­nh trá»ng sá»‘ (eigenvector) cá»§a ma tráº­n AHP vÃ  Tá»· lá»‡ nháº¥t quÃ¡n (CR)."""
    try:
        A = np.array(comparison_matrix)
        n = A.shape[0]

        eigenvalues, eigenvectors = np.linalg.eig(A)
        max_eigen_value = np.max(eigenvalues.real)
        
        max_eigen_vector_index = np.argmax(eigenvalues.real)
        weights = eigenvectors[:, max_eigen_vector_index].real
        weights = weights / weights.sum()
        
        CI = (max_eigen_value - n) / (n - 1) if n > 1 else 0
        
        RI_values = {1: 0.00, 2: 0.00, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45, 10: 1.49}
        RI = RI_values.get(n, 1.49) 

        CR = CI / RI if RI != 0 else 0
        
        return weights, CR, pd.DataFrame(A)
    except Exception as e:
        st.error(f"Lá»—i tÃ­nh toÃ¡n AHP: {e}")
        n_crit = len(comparison_matrix)
        return np.array([1/n_crit for _ in range(n_crit)]), 1.0, pd.DataFrame(np.identity(n_crit))


def run_topsis(decision_matrix, weights, impacts):
    """Thuáº­t toÃ¡n TOPSIS"""
    norm_matrix = decision_matrix / np.sqrt((decision_matrix**2).sum(axis=0))
    weighted_matrix = norm_matrix * weights
    
    impacts_arr = np.array([1 if i == 'Benefit' else -1 for i in impacts])
    
    ideal_best = np.where(impacts_arr == 1, weighted_matrix.max(axis=0), weighted_matrix.min(axis=0))
    ideal_worst = np.where(impacts_arr == -1, weighted_matrix.max(axis=0), weighted_matrix.min(axis=0))

    dist_to_best = np.sqrt(((weighted_matrix - ideal_best)**2).sum(axis=1))
    dist_to_worst = np.sqrt(((weighted_matrix - ideal_worst)**2).sum(axis=1))
    
    epsilon = 1e-6
    return dist_to_worst / (dist_to_best + dist_to_worst + epsilon)

# === CÃC HÃ€M TIá»†N ÃCH KHÃC ===
def generate_analysis_text(results_df, weights, impacts):
    """Táº¡o ra cÃ¡c Ä‘oáº¡n vÄƒn báº£n phÃ¢n tÃ­ch vÃ  gá»£i Ã½"""
    if results_df.empty: return "", "", ""
    
    best_stock_name = results_df.index[0]
    worst_stock_name = results_df.index[-1]
    best_stock_data = results_df.iloc[0]
    worst_stock_data = results_df.iloc[-1]
    
    impact_map = {'Benefit': 1, 'Cost': -1}
    numerical_impacts = {k: impact_map[v] for k, v in impacts.items()}

    best_reasons = []
    for crit, impact_val in numerical_impacts.items():
        if crit not in results_df.columns: continue
        val = best_stock_data[crit]
        if (impact_val == 1 and val >= results_df[crit].quantile(0.75)) or \
           (impact_val == -1 and val <= results_df[crit].quantile(0.25)):
            best_reasons.append(f"**{crit}** ({val:.2f})")

    best_analysis = f"ğŸ† **{best_stock_name}** Ä‘Æ°á»£c xáº¿p háº¡ng cao nháº¥t. Äiá»ƒm máº¡nh chÃ­nh Ä‘áº¿n tá»« cÃ¡c chá»‰ sá»‘: {', '.join(best_reasons[:3])}."
    
    worst_reasons = []
    for crit, impact_val in numerical_impacts.items():
        if crit not in results_df.columns: continue
        val = worst_stock_data[crit]
        if (impact_val == 1 and val <= results_df[crit].quantile(0.25)) or \
           (impact_val == -1 and val >= results_df[crit].quantile(0.75)):
            worst_reasons.append(f"**{crit}** ({val:.2f})")
    
    worst_analysis = f"âš ï¸ **{worst_stock_name}** cÃ³ rá»§i ro cao nháº¥t trong danh sÃ¡ch, chá»§ yáº¿u do cÃ¡c chá»‰ sá»‘ chÆ°a tá»‘t nhÆ°: {', '.join(worst_reasons[:3])}."

    actionable_advice = """
    ğŸ’¡ **Gá»£i Ã½ hÃ nh Ä‘á»™ng:**
    - **Äá»‘i vá»›i cÃ¡c cá»• phiáº¿u top Ä‘áº§u:** ÄÃ¢y lÃ  nhá»¯ng á»©ng viÃªn sÃ¡ng giÃ¡. HÃ£y cÃ¢n nháº¯c Ä‘Æ°a vÃ o danh sÃ¡ch theo dÃµi vÃ  **phÃ¢n tÃ­ch sÃ¢u hÆ¡n** vá» yáº¿u tá»‘ cÆ¡ báº£n cá»§a doanh nghiá»‡p.
    - **Äá»‘i vá»›i cÃ¡c cá»• phiáº¿u cuá»‘i báº£ng:** Cáº§n tháº­n trá»ng. Náº¿u Ä‘ang náº¯m giá»¯, báº¡n nÃªn **xem xÃ©t láº¡i vá»‹ tháº¿** vÃ  cÃ³ thá»ƒ Ä‘áº·t cÃ¡c biá»‡n phÃ¡p phÃ²ng ngá»«a rá»§i ro nhÆ° **lá»‡nh cáº¯t lá»— (stop-loss)**.
    - **LÆ°u Ã½:** Káº¿t quáº£ nÃ y hoÃ n toÃ n dá»±a trÃªn cÃ¡c chá»‰ sá»‘ vÃ  trá»ng sá»‘ báº¡n Ä‘Ã£ cung cáº¥p. ÄÃ¢y lÃ  cÃ´ng cá»¥ tham kháº£o, khÃ´ng pháº£i lá»i khuyÃªn Ä‘áº§u tÆ°.
    """
    
    return best_analysis, worst_analysis, actionable_advice

def format_large_number(num):
    """Äá»‹nh dáº¡ng sá»‘ lá»›n (vd: vá»‘n hÃ³a) thÃ nh dáº¡ng tá»·, triá»‡u."""
    if pd.isna(num): return "N/A"
    num = float(num)
    if num >= 1e12: return f"{num / 1e12:.2f} nghÃ¬n tá»·"
    if num >= 1e9: return f"{num / 1e9:.2f} tá»·"
    if num >= 1e6: return f"{num / 1e6:.2f} triá»‡u"
    return f"{num:,.2f}"

# --- GIAO DIá»†N CHÃNH ---
st.title("âš–ï¸ á»¨ng dá»¥ng PhÃ¢n tÃ­ch Rá»§i ro Äáº§u tÆ° Cá»• phiáº¿u báº±ng TOPSIS vÃ  AHP")
st.info("ğŸ¯ Xáº¿p háº¡ng rá»§i ro cá»• phiáº¿u dá»±a trÃªn cÃ¡c chá»‰ sá»‘ tÃ i chÃ­nh vá»›i trá»ng sá»‘ tÃ¹y chá»‰nh (cÃ³ thá»ƒ dÃ¹ng AHP Ä‘á»ƒ tÃ­nh trá»ng sá»‘)")

# --- THANH ÄIá»€U KHIá»‚N (SIDEBAR) ---
with st.sidebar:
    st.header("âš™ï¸ Báº£ng Ä‘iá»u khiá»ƒn")
    data_source = st.radio("ğŸ“‚ Chá»n nguá»“n dá»¯ liá»‡u:", ["Yahoo Finance API", "Database MySQL"], key="data_source")

    weights = {}
    CR = 1.0 
    
    if data_source == "Yahoo Finance API":
        criteria_yf = {'Beta': -1, 'P/E': -1, 'Ná»£/Vá»‘n CSH': -1, 'ROE': 1, 'BiÃªn LN': 1}
        criteria_list = list(criteria_yf.keys())
        n_criteria = len(criteria_list)
        tickers_input = st.text_area("Nháº­p mÃ£ cá»• phiáº¿u (phÃ¢n cÃ¡ch bá»Ÿi dáº¥u pháº©y):", "AAPL, MSFT, GOOGL, TSLA, NVDA")
        col_impacts = {k: ('Benefit' if v == 1 else 'Cost') for k, v in criteria_yf.items()}
    else:
        criteria_list = DB_CRITERIA
        n_criteria = len(criteria_list)
        col_impacts = DB_IMPACTS

    st.header("âš–ï¸ Thiáº¿t láº­p Trá»ng sá»‘")
    
    tab_ahp, tab_manual = st.tabs(["ğŸ”¢ TÃ­nh Trá»ng sá»‘ báº±ng AHP", "ğŸ› ï¸ Nháº­p Trá»ng sá»‘ Thá»§ cÃ´ng"])

    # ----------------------------------------------------
    # TAB 1: TÃNH TRá»ŒNG Sá» Báº°NG AHP
    # ----------------------------------------------------
    with tab_ahp:
        with st.expander("âš–ï¸ So sÃ¡nh Ä‘á»™ quan trá»ng cá»§a cÃ¡c tiÃªu chÃ­ (Nháº­p liá»‡u)", expanded=True):
            for crit_i, crit_j in itertools.combinations(criteria_list, 2):
                impact_display_i = f" (*{col_impacts.get(crit_i, '')}*)" if data_source != "Yahoo Finance API" else ""
                impact_display_j = f" (*{col_impacts.get(crit_j, '')}*)" if data_source != "Yahoo Finance API" else ""

                comparison_value = st.select_slider(
                    f"**{crit_i}**{impact_display_i} quan trá»ng hÆ¡n **{crit_j}**{impact_display_j}?",
                    options=[1/9, 1/8, 1/7, 1/6, 1/5, 1/4, 1/3, 1/2, 1, 2, 3, 4, 5, 6, 7, 8, 9],
                    value=1.0,
                    format_func=lambda x: f"1/{round(1/x)}" if x < 1 else str(round(x)),
                    key=f"ahp_{crit_i}_{crit_j}_{data_source}",
                    help=f"So sÃ¡nh {CRITERIA_EXPLANATIONS.get(crit_i)} vs {CRITERIA_EXPLANATIONS.get(crit_j)}"
                )
                st.session_state[f'ahp_comp_{crit_i}_{crit_j}'] = comparison_value

        comparison_matrix = [[0.0] * n_criteria for _ in range(n_criteria)]
        for i in range(n_criteria):
            for j in range(n_criteria):
                if i == j:
                    comparison_matrix[i][j] = 1.0
                elif i < j:
                    crit_i, crit_j = criteria_list[i], criteria_list[j]
                    comp_val = st.session_state.get(f'ahp_comp_{crit_i}_{crit_j}', 1.0)
                    comparison_matrix[i][j] = comp_val
                else:
                    comparison_matrix[i][j] = 1.0 / comparison_matrix[j][i]
                    
        ahp_weights_array, CR, AHP_Matrix_df = calculate_ahp_weights(comparison_matrix)
        
        st.session_state['weights_source'] = 'AHP'
        st.session_state['CR'] = CR
        st.session_state['AHP_Matrix_df'] = AHP_Matrix_df
        st.session_state['ahp_weights'] = {criteria_list[i]: ahp_weights_array[i] for i in range(n_criteria)}

        st.markdown("---")
        with st.expander("ğŸ’¡ Giáº£i thÃ­ch Tá»· lá»‡ nháº¥t quÃ¡n (CR)"):
            st.info(
                """
                **CR (Consistency Ratio)** Ä‘o lÆ°á»ng má»©c Ä‘á»™ logic vÃ  khÃ´ng mÃ¢u thuáº«n trong cÃ¡c so sÃ¡nh cáº·p cá»§a báº¡n.
                - **CR â‰¤ 0.1 (Tá»‘t):** CÃ¡c Ä‘Ã¡nh giÃ¡ nháº¥t quÃ¡n, káº¿t quáº£ Ä‘Ã¡ng tin cáº­y.
                - **CR > 0.1 (Cáº§n xem láº¡i):** CÃ³ sá»± mÃ¢u thuáº«n (VD: A > B, B > C, nhÆ°ng C > A). 
                
                Báº¡n nÃªn Ä‘iá»u chá»‰nh láº¡i cÃ¡c so sÃ¡nh Ä‘á»ƒ káº¿t quáº£ Ä‘Ã¡ng tin cáº­y hÆ¡n.
                """
            )

        with st.expander("ğŸ“Š Káº¿t quáº£ AHP (Trá»ng sá»‘ & CR)", expanded=True):
            st.markdown(f"**Tá»· lá»‡ nháº¥t quÃ¡n (CR):**")
            st.code(f"{CR:.4f}", language=None)
            if CR > 0.1:
                st.error("âš ï¸ CR > 0.1. Má»©c Ä‘á»™ nháº¥t quÃ¡n tháº¥p.")
            else:
                st.success("âœ… CR â‰¤ 0.1. Má»©c Ä‘á»™ nháº¥t quÃ¡n cháº¥p nháº­n Ä‘Æ°á»£c.")
                
            weights_df = pd.DataFrame(st.session_state['ahp_weights'].items(), columns=['TiÃªu chÃ­', 'Trá»ng sá»‘']).set_index('TiÃªu chÃ­')
            st.markdown("**Trá»ng sá»‘ Ä‘Æ°á»£c tÃ­nh toÃ¡n:**")
            st.dataframe(weights_df.style.format("{:.4f}"))

        with st.expander("ğŸ“‹ Xem Ma tráº­n So sÃ¡nh Cáº·p (Äáº§u vÃ o AHP)"):
            AHP_Matrix_df.columns = criteria_list
            AHP_Matrix_df.index = criteria_list
            st.dataframe(AHP_Matrix_df.style.format("{:.3f}").background_gradient(cmap='Blues', axis=None), use_container_width=True)

    # ----------------------------------------------------
    # TAB 2: NHáº¬P TRá»ŒNG Sá» THá»¦ CÃ”NG
    # ----------------------------------------------------
    with tab_manual:
        st.subheader("Nháº­p Trá»ng sá»‘ Thá»§ cÃ´ng")
        
        default_weights = {k: 1.0 / n_criteria for k in criteria_list}
        
        if data_source == "Yahoo Finance API":
            preset = st.selectbox("ğŸšï¸ Chá»n bá»™ trá»ng sá»‘ máº«u:", ["TÃ¹y chá»‰nh", "An toÃ n", "CÃ¢n báº±ng", "TÄƒng trÆ°á»Ÿng"], key="preset_yf_man")

            if preset == "An toÃ n": default_weights = {'Beta': 0.3, 'P/E': 0.2, 'Ná»£/Vá»‘n CSH': 0.3, 'ROE': 0.1, 'BiÃªn LN': 0.1}
            elif preset == "CÃ¢n báº±ng": default_weights = {'Beta': 0.2, 'P/E': 0.2, 'Ná»£/Vá»‘n CSH': 0.2, 'ROE': 0.2, 'BiÃªn LN': 0.2}
            elif preset == "TÄƒng trÆ°á»Ÿng": default_weights = {'Beta': 0.1, 'P/E': 0.1, 'Ná»£/Vá»‘n CSH': 0.1, 'ROE': 0.35, 'BiÃªn LN': 0.35}
        
        manual_weights = {}
        for crit in criteria_list:
            impact_display = f" (*{col_impacts.get(crit, '')}*)" if data_source != "Yahoo Finance API" else ""
            manual_weights[crit] = st.slider(
                f"ğŸ¯ {crit}{impact_display}", 0.0, 1.0, default_weights.get(crit, 1.0/n_criteria), 0.05, 
                key=f'w_{crit}_man_slider', help=CRITERIA_EXPLANATIONS.get(crit, "")
            )
        
        st.session_state['weights_source'] = 'Manual'
        st.session_state['manual_weights'] = manual_weights
        st.session_state['CR'] = 0.0 

    # ----------------------------------------------------
    # LOGIC CHUNG SAU KHI THIáº¾T Láº¬P TRá»ŒNG Sá»
    # ----------------------------------------------------
    if st.session_state.get('weights_source') == 'AHP':
        weights = st.session_state.get('ahp_weights', {})
        CR = st.session_state.get('CR', 1.0)
    elif st.session_state.get('weights_source') == 'Manual':
        weights = st.session_state.get('manual_weights', {})
        CR = 0.0
    
    total_weight = sum(weights.values())
    st.markdown("---")
    st.markdown("**Tráº¡ng thÃ¡i Trá»ng sá»‘ Hiá»‡n táº¡i**")
    if abs(total_weight - 1.0) > 0.01 and st.session_state.get('weights_source') == 'Manual':
        st.warning(f"âš ï¸ Tá»•ng trá»ng sá»‘: {total_weight:.2f} (Cáº§n = 1.0)")
    else:
        st.success(f"âœ… Tá»•ng trá»ng sá»‘: {total_weight:.2f}")

# --- NÃšT PHÃ‚N TÃCH VÃ€ HIá»‚N THá»Š Káº¾T QUáº¢ ---
if st.button("ğŸš€ Báº¯t Ä‘áº§u PhÃ¢n tÃ­ch", use_container_width=True):
    
    CR = st.session_state.get('CR', 1.0)
    
    if CR > 0.1:
        st.error("CR > 0.1. Vui lÃ²ng Ä‘iá»u chá»‰nh láº¡i cÃ¡c so sÃ¡nh cáº·p trong Tab AHP Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh nháº¥t quÃ¡n trÆ°á»›c khi phÃ¢n tÃ­ch.")
        st.stop()
        
    if not weights or sum(weights.values()) == 0:
        st.error("âŒ Trá»ng sá»‘ khÃ´ng há»£p lá»‡. Vui lÃ²ng thiáº¿t láº­p trá»ng sá»‘ trong báº£ng Ä‘iá»u khiá»ƒn.")
        st.stop()
        
    normalized_weights = {k: v / sum(weights.values()) for k, v in weights.items()}
    
    raw_data = pd.DataFrame()
    if data_source == "Yahoo Finance API":
        tickers_list = [t.strip().upper() for t in tickers_input.split(',') if t.strip()]
        if not tickers_list:
            st.error("âŒ Vui lÃ²ng nháº­p Ã­t nháº¥t má»™t mÃ£ cá»• phiáº¿u.")
            st.stop()

        with st.spinner(f"â³ Äang táº£i dá»¯ liá»‡u cho {len(tickers_list)} cá»• phiáº¿u..."):
            raw_data = get_stock_data(tickers_list)
        
        criteria = {k: ('Benefit' if v == 1 else 'Cost') for k, v in criteria_yf.items()}
    else:
        with st.spinner("â³ Äang káº¿t ná»‘i vÃ  xá»­ lÃ½ dá»¯ liá»‡u tá»« database..."):
            conn = get_db_connection()
            if not conn: st.stop()
            
            df_raw = get_data_from_db(conn)
            if df_raw.empty: st.stop()

            ticker_col = 'Ticker'
            if ticker_col not in df_raw.columns:
                st.error(f"âŒ KhÃ´ng tÃ¬m tháº¥y cá»™t '{ticker_col}' trong database.")
                st.stop()

            df_raw['Date'] = pd.to_datetime(df_raw.get('Date'), errors='coerce')
            df_grouped = df_raw.sort_values('Date', ascending=True).groupby(ticker_col).last().reset_index()
            
            missing_cols = [col for col in DB_CRITERIA if col not in df_grouped.columns]
            if missing_cols:
                st.error(f"âŒ Database thiáº¿u cÃ¡c cá»™t: {', '.join(missing_cols)}")
                st.stop()

            st.success(f"âœ… ÄÃ£ xá»­ lÃ½ {len(df_grouped)} mÃ£ cá»• phiáº¿u.")
        
        raw_data = df_grouped.set_index(ticker_col)[DB_CRITERIA].copy()
        raw_data.index.name = 'MÃ£ CP'

        for col in raw_data.columns:
            raw_data[col] = pd.to_numeric(raw_data[col], errors='coerce').fillna(raw_data[col].median())
        criteria = DB_IMPACTS

    if raw_data.empty:
        st.error("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ phÃ¢n tÃ­ch.")
        st.stop()

    st.header("ğŸ“Š Dá»¯ liá»‡u Äáº§u vÃ o sau khi xá»­ lÃ½")
    formatters = {col: "{:,.2f}" for col in raw_data.columns}
    if 'marketCap_snapshot' in raw_data.columns:
        formatters['marketCap_snapshot'] = format_large_number
    st.dataframe(raw_data.style.format(formatters).background_gradient(cmap='YlOrRd', axis=0), use_container_width=True)

    st.header("ğŸ† Káº¿t quáº£ Xáº¿p háº¡ng TOPSIS")
    decision_matrix = raw_data[list(criteria.keys())]
    weights_list = np.array([normalized_weights[crit] for crit in criteria])
    impacts_list = list(criteria.values())

    scores = run_topsis(decision_matrix.values, weights_list, impacts_list)

    results_df = raw_data.copy()
    results_df['Äiá»ƒm TOPSIS'] = scores
    results_df['Xáº¿p háº¡ng'] = results_df['Äiá»ƒm TOPSIS'].rank(ascending=False).astype(int)
    results_df = results_df.sort_values(by='Xáº¿p háº¡ng')
    
    col1, col2, col3 = st.columns(3)
    col1.metric("ğŸ¥‡ Tá»‘t nháº¥t (Ãt rá»§i ro nháº¥t)", results_df.index[0], f"{results_df['Äiá»ƒm TOPSIS'].iloc[0]:.4f}")
    col2.metric("ğŸ¥ˆ Rá»§i ro nháº¥t", results_df.index[-1], f"{results_df['Äiá»ƒm TOPSIS'].iloc[-1]:.4f}")
    col3.metric("ğŸ“Š Äiá»ƒm trung bÃ¬nh", f"{results_df['Äiá»ƒm TOPSIS'].mean():.4f}")
    
    result_formatters = {col: "{:,.4f}" for col in results_df.columns if pd.api.types.is_numeric_dtype(results_df[col]) and col not in ['Xáº¿p háº¡ng']}
    result_formatters['Äiá»ƒm TOPSIS'] = "{:.4f}"
    if 'marketCap_snapshot' in results_df.columns:
        result_formatters['marketCap_snapshot'] = format_large_number

    st.dataframe(
        results_df.style
        .apply(lambda row: ['background-color: #2E8B57; color: white; font-weight: bold' if row['Xáº¿p háº¡ng'] == 1 else '' for _ in row], axis=1)
        .background_gradient(cmap='Greens', subset=['Äiá»ƒm TOPSIS'])
        .format(result_formatters),
        use_container_width=True
    )
    
    st.markdown("---")
    st.subheader("ğŸ“ PhÃ¢n tÃ­ch vÃ  Gá»£i Ã½")
    best_analysis, worst_analysis, actionable_advice = generate_analysis_text(results_df, normalized_weights, criteria)
    st.markdown(best_analysis)
    st.markdown(worst_analysis)
    st.markdown(actionable_advice)
    st.markdown("---")

    tab1, tab2, tab3 = st.tabs(["ğŸ“Š Biá»ƒu Ä‘á»“ So sÃ¡nh", "ğŸ¯ Biá»ƒu Ä‘á»“ Radar", "ğŸ“¥ Táº£i xuá»‘ng"])
    with tab1:
        fig = px.bar(results_df, x=results_df.index, y='Äiá»ƒm TOPSIS', color='Äiá»ƒm TOPSIS',
                     color_continuous_scale='Greens', title='So sÃ¡nh Äiá»ƒm TOPSIS giá»¯a cÃ¡c Cá»• phiáº¿u', text='Äiá»ƒm TOPSIS')
        fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')
        fig.update_layout(xaxis_title="MÃ£ Cá»• phiáº¿u", yaxis_title="Äiá»ƒm TOPSIS", xaxis={'categoryorder':'total descending'})
        st.plotly_chart(fig, use_container_width=True)
    with tab2:
        top_n = min(5, len(results_df))
        top_stocks = results_df.head(top_n)
        norm_data = (top_stocks[list(criteria.keys())] - top_stocks[list(criteria.keys())].min()) / \
                      (top_stocks[list(criteria.keys())].max() - top_stocks[list(criteria.keys())].min())
        fig_radar = go.Figure()
        for ticker in top_stocks.index:
            fig_radar.add_trace(go.Scatterpolar(r=norm_data.loc[ticker].values, theta=list(criteria.keys()), fill='toself', name=ticker))
        fig_radar.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 1])), showlegend=True, title=f"So sÃ¡nh Top {top_n} Cá»• phiáº¿u (dá»¯ liá»‡u Ä‘Ã£ chuáº©n hÃ³a)")
        st.plotly_chart(fig_radar, use_container_width=True)
    with tab3:
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            results_df.to_excel(writer, sheet_name='Ket_qua_TOPSIS')
            raw_data.to_excel(writer, sheet_name='Du_lieu_goc')
            pd.DataFrame({
                'Chá»‰ sá»‘': list(normalized_weights.keys()),
                'Trá»ng sá»‘': list(normalized_weights.values()),
                'TÃ¡c Ä‘á»™ng': [criteria[k] for k in normalized_weights.keys()]
            }).to_excel(writer, sheet_name='Cau_hinh_phan_tich', index=False)
        
        st.download_button("ğŸ“Š Táº£i bÃ¡o cÃ¡o chi tiáº¿t (.xlsx)", output.getvalue(),
                          f"topsis_ahp_report_{datetime.now().strftime('%Y%m%d')}.xlsx",
                          "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)
    try:
        # 1. TÃ­nh toÃ¡n káº¿t quáº£ TOPSIS (Äá»™c láº­p)
        num_criteria = len(criteria)
        independent_weights_list = np.array([1 / num_criteria] * num_criteria)
        independent_scores = run_topsis(decision_matrix.values, independent_weights_list, impacts_list)
        
        independent_results_df = raw_data.copy()
        independent_results_df['Äiá»ƒm TOPSIS (Äá»™c láº­p)'] = independent_scores
        independent_results_df['Háº¡ng (Äá»™c láº­p)'] = independent_results_df['Äiá»ƒm TOPSIS (Äá»™c láº­p)'].rank(ascending=False).astype(int)
        independent_results_df = independent_results_df.sort_values(by='Háº¡ng (Äá»™c láº­p)')

        # 2. LÆ°u cáº£ 3 káº¿t quáº£ vÃ o session_state
        st.session_state['results_cr'] = CR
        st.session_state['results_topsis_independent'] = independent_results_df
        st.session_state['results_combined'] = results_df

        # 3. Äáº·t cá» bÃ¡o hiá»‡u Ä‘Ã£ cháº¡y thÃ nh cÃ´ng
        st.session_state['analysis_run_successfully'] = True

    except Exception as e:
        st.error(f"Lá»—i khi tÃ­nh toÃ¡n so sÃ¡nh: {e}")
        st.session_state['analysis_run_successfully'] = False

st.markdown("---")
st.markdown("ğŸ”¬ **TOPSIS & AHP Analysis System**")
if st.session_state.get('analysis_run_successfully', False):
    st.markdown("---")
    st.header("ğŸ ÄÃ¡nh giÃ¡ Hiá»‡u quáº£ 3 Giai Ä‘oáº¡n (Äá»‹nh lÆ°á»£ng)")

    # --- 1. ÄÃ¡nh giÃ¡ AHP (Äá»™c láº­p) ---
    st.subheader("1. Hiá»‡u quáº£ AHP (Äá»™c láº­p)")
    st.info(
        "Hiá»‡u quáº£ cá»§a AHP Ä‘Æ°á»£c Ä‘o báº±ng **Tá»· lá»‡ Nháº¥t quÃ¡n (CR)**. "
        "Chá»‰ sá»‘ nÃ y cho biáº¿t cÃ¡c so sÃ¡nh cáº·p cá»§a báº¡n cÃ³ logic vÃ  nháº¥t quÃ¡n hay khÃ´ng."
    )

    cr_score = st.session_state.get('results_cr', 1.0)
    st.metric(label="Tá»· lá»‡ Nháº¥t quÃ¡n (CR)", value=f"{cr_score:.4f}")
    if cr_score <= 0.1:
        st.success("âœ… **ÄÃ¡nh giÃ¡: Hiá»‡u quáº£.** (CR <= 0.1). CÃ¡c so sÃ¡nh cá»§a báº¡n nháº¥t quÃ¡n, bá»™ trá»ng sá»‘ Ä‘Ã¡ng tin cáº­y.")
    else:
        st.error("âš ï¸ **ÄÃ¡nh giÃ¡: KhÃ´ng Hiá»‡u quáº£.** (CR > 0.1). CÃ¡c so sÃ¡nh cá»§a báº¡n mÃ¢u thuáº«n. Cáº§n xem láº¡i cÃ¡c so sÃ¡nh cáº·p trong tab AHP.")

    # --- 2. ÄÃ¡nh giÃ¡ TOPSIS (Äá»™c láº­p) ---
    st.subheader("2. Hiá»‡u quáº£ TOPSIS (Äá»™c láº­p)")
    st.info(
        "Báº£n thÃ¢n TOPSIS Ä‘á»™c láº­p (vá»›i trá»ng sá»‘ báº±ng nhau) khÃ´ng cÃ³ 'Ä‘iá»ƒm hiá»‡u quáº£'. "
        "Vai trÃ² cá»§a nÃ³ lÃ  táº¡o ra má»™t **Xáº¿p háº¡ng CÆ¡ sá»Ÿ (Baseline)** Ä‘á»ƒ lÃ m ná»n so sÃ¡nh."
    )
    st.markdown("Xem Xáº¿p háº¡ng CÆ¡ sá»Ÿ trong báº£ng so sÃ¡nh bÃªn dÆ°á»›i.")

    # --- 3. ÄÃ¡nh giÃ¡ Káº¿t há»£p (AHP + TOPSIS) ---
    st.subheader("3. Hiá»‡u quáº£ Káº¿t há»£p (AHP + TOPSIS)")
    st.info(
        "Hiá»‡u quáº£ cá»§a mÃ´ hÃ¬nh káº¿t há»£p Ä‘Æ°á»£c Ä‘o báº±ng **má»©c Ä‘á»™ tÃ¡c Ä‘á»™ng** cá»§a AHP lÃªn káº¿t quáº£ cá»§a TOPSIS. "
        "ChÃºng ta dÃ¹ng **Há»‡ sá»‘ TÆ°Æ¡ng quan Háº¡ng Spearman (Rho)** Ä‘á»ƒ Ä‘o lÆ°á»ng Ä‘iá»u nÃ y."
    )
    try:
        # Láº¥y 2 báº£ng xáº¿p háº¡ng
        df_combined = st.session_state['results_combined']['Xáº¿p háº¡ng']
        df_independent = st.session_state['results_topsis_independent']['Háº¡ng (Äá»™c láº­p)']
        
        # CÄƒn chá»‰nh 2 báº£ng theo index (MÃ£ CP) Ä‘á»ƒ Ä‘áº£m báº£o so sÃ¡nh Ä‘Ãºng
        df_independent = df_independent.reindex(df_combined.index)
        
        # TÃ­nh toÃ¡n tÆ°Æ¡ng quan háº¡ng
        correlation, p_value = spearmanr(df_combined, df_independent)      
        st.metric(label="Há»‡ sá»‘ TÆ°Æ¡ng quan Háº¡ng (Spearman's Rho)", value=f"{correlation:.4f}")     

        interpretation = ""
        if correlation > 0.8:
            interpretation = ("**Giá»‘ng nhau (TÆ°Æ¡ng quan > 0.8):** "
                            "Viá»‡c dÃ¹ng AHP gáº§n nhÆ° **khÃ´ng lÃ m thay Ä‘á»•i** káº¿t quáº£ xáº¿p háº¡ng. Äiá»u nÃ y xáº£y ra khi cÃ¡c trá»ng sá»‘ AHP gáº§n báº±ng nhau.")
        elif correlation > 0.4:
            interpretation = ("**KhÃ¡ tÆ°Æ¡ng Ä‘á»“ng (TÆ°Æ¡ng quan 0.4 - 0.8):** "
                            "Viá»‡c dÃ¹ng AHP **cÃ³ Ä‘iá»u chá»‰nh** thá»© háº¡ng, nhÆ°ng xu hÆ°á»›ng chung váº«n Ä‘Æ°á»£c giá»¯ nguyÃªn.")
        else:
            interpretation = ("**Ráº¥t khÃ¡c biá»‡t (TÆ°Æ¡ng quan < 0.4):** "
                            "Viá»‡c dÃ¹ng AHP Ä‘Ã£ **thay Ä‘á»•i Ä‘Ã¡ng ká»ƒ** káº¿t quáº£, chá»©ng tá» trá»ng sá»‘ cá»§a báº¡n cÃ³ tÃ¡c Ä‘á»™ng lá»›n.")
        
        st.success(
            f"""
            **Giáº£i thÃ­ch:**
            - Gáº§n **1.0**: Hai báº£ng xáº¿p háº¡ng y há»‡t nhau.
            - Gáº§n **0.0**: Hai báº£ng xáº¿p háº¡ng khÃ´ng liÃªn quan.
            **ÄÃ¡nh giÃ¡ cá»§a báº¡n:** {interpretation}
            """
        )

    except Exception as e:
        st.error(f"Lá»—i tÃ­nh toÃ¡n tÆ°Æ¡ng quan: {e}")